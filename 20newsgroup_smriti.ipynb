{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAL GUIDLINES\n",
    "# 20 different categories\n",
    "# each category has around 1000 docs.\n",
    "# train a classfier \n",
    "# remove words with freq 1, 2\n",
    "# don't add stop words in dictonary\n",
    "# sort dictonary\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import string\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import math as ma\n",
    "\n",
    "#a simple helper function to convert a 2D array to 1D, without using numpy\n",
    "def flatten(list):\n",
    "    new_list = []\n",
    "    for i in list:\n",
    "        for j in i:\n",
    "            new_list.append(j)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data in terms of x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_y(my_path):\n",
    "    folders = []\n",
    "\n",
    "    for f in listdir(my_path):\n",
    "        if f != '.DS_Store':\n",
    "            folders.append(f) \n",
    "            \n",
    "    #---------\n",
    "    \n",
    "    files = []\n",
    "    for folder_name in folders:\n",
    "        folder_path = join(my_path, folder_name)\n",
    "        files.append([f for f in listdir(folder_path)])\n",
    "        \n",
    "    #----------\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    for fo in range(len(folders)):\n",
    "        for fi in files[fo]:\n",
    "            y.append(folders[fo])\n",
    "            x.append(join(my_path, join(folders[fo], fi)))\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "x, y = get_x_y(\"20_newsgroups\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Train and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14997"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_x_train, doc_x_test, doc_y_train, doc_y_test = train_test_split(x, y, random_state=0, test_size=0.25)\n",
    "len(doc_x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preporcess remove stop words and preprocess words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=np.loadtxt('https://a5a5687e-a-62cb3a1a-s-sites.googlegroups.com/site/kevinbouge/stopwords-lists/stopwords_en.txt?attachauth=ANoY7crcABAfBg6e5ZA_6lZ79_r4NuPw2j4KdOLBq9sySv5C18RCykRhnGoN-pG2hfvk4B2jqk2lDxK5Al2FVEfUXu4dbWV-7HDgYA7JrFSMyvIu7r9BNi1uAPe_wiuEFCLptEBoK3D3NOBv-un9McQ2nVZ2RsPF1EQmwLN3n7wS6OlSWMUeI6xaXvU_Tvsqwi5DQOOaIx6zw11Ry6wptN3n3aUuF8Tw8wJYhWoPQCpKTZ0eukRtmvk%3D&attredirects=0&d=1',dtype= str , delimiter=',').tolist()\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    words = [word for word in words if not word in stopwords]\n",
    "    return words\n",
    "\n",
    "def preprocess(words):\n",
    "    #we'll make use of python's translate function,that maps one set of characters to another\n",
    "    #we create an empty mapping table, the third argument allows us to list all of the characters we want to delete\n",
    "    \n",
    "    #first we will try to filter out some  unnecessary data like tabs, punctuation\n",
    "    \n",
    "    # the character: ' appears in a lot of stopwords and changes meaning of words if removed\n",
    "    #hence it is removed from the list of symbols that are to be discarded from the documents\n",
    "    \n",
    "    p = (string.punctuation).replace(\"'\", \"\")  + \"\\t\"\n",
    "    table = str.maketrans('', '', p)\n",
    "    words = [word.translate(table) for word in words]\n",
    "    \n",
    "    \n",
    "    #some white spaces may be added to the list of words, due to the translate function & nature of our documents\n",
    "    #we remove them below\n",
    "    words = [str for str in words if str]\n",
    "        \n",
    "    #we will also remove just-numeric strings as they do not have any significant meaning in text classification\n",
    "    words = [word for word in words if not word.isdigit()]\n",
    "    \n",
    "    #after removal of so many characters it may happen that some strings have become blank, we remove those\n",
    "    words = [str for str in words if str]\n",
    "    \n",
    "    #we also normalize the cases of our words\n",
    "    words = [word.lower() for word in words]\n",
    "    \n",
    "    #we try to remove words with only 2 characters or 1 character\n",
    "    words = [word for word in words if len(word) > 2]\n",
    "    \n",
    "    return words\n",
    "\n",
    "\n",
    "\n",
    "def tokenize_sentence(line):\n",
    "    words = line.strip().split(\" \")\n",
    "    words = preprocess(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words\n",
    "\n",
    "\n",
    "#function to convert a document into list of words\n",
    "\n",
    "def tokenize(path):\n",
    "    #load document as a list of lines\n",
    "    f = open(path, 'r', encoding=\"utf8\", errors='ignore')\n",
    "    text_lines = f.readlines()\n",
    "    \n",
    "    #initiazing an array to hold all the words in a document\n",
    "    doc_words = []\n",
    "    \n",
    "    #traverse over all the lines and tokenize each one with the help of helper function: tokenize_sentence\n",
    "    for line in text_lines:\n",
    "        doc_words.append(tokenize_sentence(line))\n",
    "\n",
    "    return doc_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get train data in freq format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_train_words_per_doc = []\n",
    "\n",
    "for document in doc_x_train:\n",
    "    list_of_train_words_per_doc.append(flatten(tokenize(document)))\n",
    "    \n",
    "list_of_words = np.array(flatten(list_of_train_words_per_doc))\n",
    "\n",
    "\n",
    "words, counts = np.unique(list_of_words, return_counts=True)\n",
    "freq, wrds = (list(i) for i in zip(*(sorted(zip(counts, words), reverse=True))))\n",
    "\n",
    "n = 2000\n",
    "features = wrds[0:n]\n",
    "\n",
    "\n",
    "dictionary_train = {}\n",
    "doc_num = 1\n",
    "for doc_words in list_of_train_words_per_doc:\n",
    "    np_doc_words = np.array(doc_words)\n",
    "    w, c = np.unique(np_doc_words, return_counts=True)\n",
    "    dictionary_train[doc_num] = dict(zip(w,c))\n",
    "    doc_num = doc_num + 1\n",
    "\n",
    "#now we make a 2D array having the frequency of each word of our feature set in each individual documents\n",
    "\n",
    "x_train = []\n",
    "for k in dictionary_train.keys():\n",
    "    row = []\n",
    "    for f in features:\n",
    "        if(f in dictionary_train[k].keys()):\n",
    "            #if word f is present in the dictionary of the document as a key, its value is copied\n",
    "            #this gives us no. of occurences\n",
    "            row.append(dictionary_train[k][f]) \n",
    "        else:\n",
    "            #if not present, the no. of occurences is zero\n",
    "            row.append(0)\n",
    "    x_train.append(row)\n",
    "    \n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(doc_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get test data in freq format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_test_words_per_doc = []\n",
    "\n",
    "for document in doc_x_test:\n",
    "        list_of_test_words_per_doc.append(flatten(tokenize(document)))\n",
    "        \n",
    "\n",
    "dictionary_test = {}\n",
    "doc_num = 1\n",
    "for doc_words in list_of_test_words_per_doc:\n",
    "    #print(doc_words)\n",
    "    np_doc_words = np.array(doc_words)\n",
    "    w, c = np.unique(np_doc_words, return_counts=True)\n",
    "    dictionary_test[doc_num] = dict(zip(w,c))\n",
    "    doc_num = doc_num + 1\n",
    "    \n",
    "\n",
    "#now we make a 2D array having the frequency of each word of our feature set in each individual documents\n",
    "\n",
    "x_test = []\n",
    "for k in dictionary_test.keys():\n",
    "    row = []\n",
    "    for f in features:\n",
    "        if(f in dictionary_test[k].keys()):\n",
    "            #if word f is present in the dictionary of the document as a key, its value is copied\n",
    "            #this gives us no. of occurences\n",
    "            row.append(dictionary_test[k][f]) \n",
    "        else:\n",
    "            #if not present, the no. of occurences is zero\n",
    "            row.append(0)\n",
    "    x_test.append(row)\n",
    "    \n",
    "\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(doc_y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKlearn Classifier. Accuracy/Score - 0.86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_predict = clf.predict(x_test)\n",
    "\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.73      0.80      0.76       240\n",
      "           comp.graphics       0.80      0.77      0.78       244\n",
      " comp.os.ms-windows.misc       0.84      0.82      0.83       240\n",
      "comp.sys.ibm.pc.hardware       0.87      0.84      0.85       256\n",
      "   comp.sys.mac.hardware       0.87      0.92      0.90       249\n",
      "          comp.windows.x       0.92      0.86      0.89       233\n",
      "            misc.forsale       0.79      0.90      0.84       259\n",
      "               rec.autos       0.88      0.92      0.90       253\n",
      "         rec.motorcycles       0.89      0.96      0.92       231\n",
      "      rec.sport.baseball       0.97      0.98      0.97       236\n",
      "        rec.sport.hockey       0.97      0.98      0.98       261\n",
      "               sci.crypt       0.96      0.92      0.94       269\n",
      "         sci.electronics       0.83      0.88      0.85       246\n",
      "                 sci.med       0.96      0.88      0.92       284\n",
      "               sci.space       0.90      0.92      0.91       248\n",
      "  soc.religion.christian       0.95      0.99      0.97       281\n",
      "      talk.politics.guns       0.73      0.86      0.79       253\n",
      "   talk.politics.mideast       0.93      0.81      0.86       233\n",
      "      talk.politics.misc       0.74      0.67      0.70       248\n",
      "      talk.religion.misc       0.64      0.48      0.55       236\n",
      "\n",
      "                accuracy                           0.86      5000\n",
      "               macro avg       0.86      0.86      0.86      5000\n",
      "            weighted avg       0.86      0.86      0.86      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_predict))                 # Print classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X_train, Y_train):                                          # This function is used to fit training data into our model\n",
    "    result = {}                                                     # This dictionary is going to be useful in later calculations\n",
    "    class_values = set(Y_train) \n",
    "    for current_class in class_values:                              # We create keys for all the possible classes\n",
    "        result[current_class] = {}                                  # We create a dictionary as value for each key itself\n",
    "        current_class_rows = (Y_train == current_class)             # Obtain rows for the current class\n",
    "        X_train_current = X_train[current_class_rows]               # Filter the x_train for current class\n",
    "        Y_train_current = Y_train[current_class_rows]               # Filter the y_train for current class\n",
    "        num_features = X_train.shape[1]                             \n",
    "        result[current_class][\"count\"] = len(Y_train_current)       # It gives total number of features of our data\n",
    "        a=0                                                         # To get total number of a particular feature \n",
    "        for j in range(num_features):                               # traverse each feature\n",
    "            result[current_class][j]=X_train_current[:,j].sum()     # Get total number of current feature\n",
    "            a+=result[current_class][j]                             # Increment a by total number of current feature\n",
    "        result[current_class]['total']=a                            # Assign a, will be used in later calculations\n",
    "    result[\"total\"] = len(Y_train)                                  # It gives total element present in our dictionary\n",
    "    return result                                                   # Return result\n",
    "\n",
    "\n",
    "\n",
    "def probability(dictionary, x, current_class): \n",
    "    output = ma.log(dictionary[current_class][\"total\"]) - ma.log(dictionary[\"total\"])\n",
    "    num_features = len(dictionary[current_class].keys()) - 2\n",
    "    for j in range( num_features ):\n",
    "        if x[j]==0:\n",
    "            continue\n",
    "        count_current_class_with_value_j = dictionary[current_class][j]+1\n",
    "        count_current_class = dictionary[current_class]['total']+num_features\n",
    "        current_j_probablity = ma.log(count_current_class_with_value_j) - ma.log(count_current_class)\n",
    "        output = output + current_j_probablity\n",
    "    return output\n",
    "\n",
    "def doSinglePrediction(x,dictionary):                                  # Function to predict class for a single row\n",
    "    classes = dictionary.keys()                                        # Get all possible classes\n",
    "    best_p = -100                                                      # Initialise best probablity & class to some -ve number\n",
    "    best_class = -100 \n",
    "    first_run = True                                                   # Running for first time = True\n",
    "    for current_class in classes:                                      # Iterate over each possible class\n",
    "        if (current_class == \"total\"):                                 # Ignore 'total' key\n",
    "            continue\n",
    "        p_current_class = probability(dictionary, x, current_class)    # Get probablity for x belonging to current class\n",
    "        if (first_run or p_current_class > best_p):                    # If this is greatest probablity till now, change the\n",
    "            best_p = p_current_class                                    # value of greatest probability & predicted class\n",
    "            best_class = current_class\n",
    "        first_run = False                                              # First run complete\n",
    "    return best_class                                                  # Return the predicted class out of all classes\n",
    "\n",
    "\n",
    "def predict(x_test, d):\n",
    "    y_pred = []\n",
    "    for x in x_test:\n",
    "        x_class = doSinglePrediction(x, dictionary)\n",
    "        y_pred.append(x_class)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = predict(x_test, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8682"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.75      0.81      0.78       240\n",
      "           comp.graphics       0.82      0.84      0.83       244\n",
      " comp.os.ms-windows.misc       0.90      0.82      0.86       240\n",
      "comp.sys.ibm.pc.hardware       0.92      0.86      0.89       256\n",
      "   comp.sys.mac.hardware       0.89      0.92      0.90       249\n",
      "          comp.windows.x       0.94      0.85      0.89       233\n",
      "            misc.forsale       0.78      0.91      0.84       259\n",
      "               rec.autos       0.87      0.93      0.90       253\n",
      "         rec.motorcycles       0.88      0.94      0.91       231\n",
      "      rec.sport.baseball       0.96      0.99      0.97       236\n",
      "        rec.sport.hockey       0.99      0.97      0.98       261\n",
      "               sci.crypt       0.98      0.93      0.95       269\n",
      "         sci.electronics       0.81      0.90      0.85       246\n",
      "                 sci.med       0.96      0.87      0.91       284\n",
      "               sci.space       0.88      0.91      0.89       248\n",
      "  soc.religion.christian       0.98      1.00      0.99       281\n",
      "      talk.politics.guns       0.77      0.87      0.82       253\n",
      "   talk.politics.mideast       0.95      0.80      0.87       233\n",
      "      talk.politics.misc       0.68      0.67      0.67       248\n",
      "      talk.religion.misc       0.66      0.53      0.58       236\n",
      "\n",
      "                accuracy                           0.87      5000\n",
      "               macro avg       0.87      0.87      0.87      5000\n",
      "            weighted avg       0.87      0.87      0.87      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # features = ['cat','bat', 'dog', 'lot', 'fol', 'tol', 'dol']\n",
    "# # x = np.array([\n",
    "# #     [1,2,3,2,4,5,6],\n",
    "# #     [0,2,3,2,4,5,6], #b\n",
    "# #     [1,4,5,2,4,5,6], #b\n",
    "# #     [0,2,2,2,4,5,0],\n",
    "# #     [1,2,3,2,4,5,0], #b\n",
    "# #     [1,2,3,4,3,5,6],\n",
    "# #     [1,2,3,2,4,5,6] #b\n",
    "# # ])\n",
    "\n",
    "# # x_test =  np.array([\n",
    "# #     [1,2,3,4,3,5,6],\n",
    "# #     [1,2,3,4,3,5,6]\n",
    "# # ])\n",
    "\n",
    "# # y = np.array(['a','b','b','a','b','a','b'])\n",
    "# def fit(X_train, Y_train):\n",
    "#     result = {}\n",
    "#     class_values = set(Y_train)\n",
    "#     for current_class in class_values:\n",
    "#         result[current_class] = {}\n",
    "#         result[\"total_data\"] = len(Y_train)\n",
    "        \n",
    "#         current_class_rows = (Y_train == current_class)\n",
    "        \n",
    "#         X_train_current = X_train[current_class_rows]\n",
    "#         Y_train_current = Y_train[current_class_rows]\n",
    "#         num_features = X_train.shape[1]\n",
    "#         result[current_class][\"total_class_count\"] =  X_train_current.shape[0]\n",
    "#         result[current_class][\"total_no_of_words\"] =  X_train_current.sum()\n",
    "#         for j in range(0, num_features):\n",
    "#             f = features[j]\n",
    "#             result[current_class][f] = X_train_current[:,j].sum()  \n",
    "#     return result\n",
    "\n",
    "# def probability(dictionary, x, current_class):\n",
    "#     output = np.log(dictionary[current_class][\"total_class_count\"]) - np.log(dictionary[\"total_data\"])\n",
    "#     for f in features:\n",
    "#         count_current_class_with_value_xj = dictionary[current_class][f] + 1\n",
    "#         count_current_class = dictionary[current_class][\"total_no_of_words\"]+ len(features)\n",
    "#         current_xj_probablity = np.log(count_current_class_with_value_xj) - np.log(count_current_class)\n",
    "#         output = output + current_xj_probablity\n",
    "#     return output\n",
    "\n",
    "# def predictSinglePoint(dictionary, x):\n",
    "#     classes = dictionary.keys()\n",
    "#     best_p = -1000\n",
    "#     best_class = -1\n",
    "#     first_run = True\n",
    "#     for current_class in classes:\n",
    "#         if (current_class == \"total_data\"):\n",
    "#             continue\n",
    "#         p_current_class = probability(dictionary, x, current_class)\n",
    "#         if (first_run or p_current_class > best_p):\n",
    "#             best_p = p_current_class\n",
    "#             best_class = current_class\n",
    "#         first_run = False\n",
    "#     return best_class\n",
    "\n",
    "# def predict(dictionary, x_test):\n",
    "#     y_pred = []\n",
    "#     for x in x_test:\n",
    "#         x_class = predictSinglePoint(dictionary, x)\n",
    "#         y_pred.append(x_class)\n",
    "#     return y_pred\n",
    "\n",
    "# dictionary = fit(x_train, y_train)\n",
    "# Y_pred = predict(dictionary, x_test[0:100])\n",
    "# accuracy_score(y_test[0:100], Y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
